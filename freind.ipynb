{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2403951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import time # Import time for adding delays\n",
    "\n",
    "# --- Configuration ---\n",
    "# Replace with your actual API key or ensure it's in your environment variables\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_GEMINI_API_KEY\"\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "persist_directory = \"./chroma_db_financial_guide\" # Define where to save your vectorstore\n",
    "\n",
    "# --- 1. Load the Document ---\n",
    "print(\"Loading document...\")\n",
    "loader = TextLoader(\"your_financial_guide.txt\") # Replace with your actual file path\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n",
    "\n",
    "# --- 2. Split into Chunks ---\n",
    "print(\"Splitting document into chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Adjust chunk size as needed\n",
    "    chunk_overlap=200,    # Adjust overlap for better context\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks.\")\n",
    "\n",
    "# --- 3. Initialize Chroma and Add Documents in Batches ---\n",
    "print(\"Initializing Chroma DB and adding documents in batches...\")\n",
    "\n",
    "# Initialize an empty Chroma vector store first.\n",
    "# Pass the embedding function and persist directory at creation.\n",
    "# If the directory already exists and contains a Chroma DB, this will load it.\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Define your batch size to match the API limit (100 for Gemini embeddings)\n",
    "batch_size = 90 # Use a slightly smaller batch size than 100 to be safe\n",
    "\n",
    "# Loop through your chunks and add them in batches\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    batch = chunks[i:i + batch_size]\n",
    "\n",
    "    # Extract page_content from Document objects in the batch\n",
    "    batch_texts = [doc.page_content for doc in batch]\n",
    "    batch_metadatas = [doc.metadata for doc in batch]\n",
    "\n",
    "    try:\n",
    "        vectorstore.add_texts(\n",
    "            texts=batch_texts,\n",
    "            metadatas=batch_metadatas\n",
    "        )\n",
    "        print(f\"Added batch {i//batch_size + 1}/{len(chunks)//batch_size + 1} ({len(batch)} documents).\")\n",
    "        # Add a small delay between batches to help with rate limits\n",
    "        time.sleep(1) # Sleep for 1 second\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding batch {i//batch_size + 1}: {e}\")\n",
    "        # Consider adding a longer sleep or retry logic here\n",
    "        time.sleep(5) # Sleep longer on error\n",
    "\n",
    "# 4. Persist the database explicitly after adding all documents\n",
    "vectorstore.persist()\n",
    "print(\"Vector store created and persisted successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
