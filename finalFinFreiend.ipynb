{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d7f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- FAISS and Local Model Imports ---\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "# --- LangChain Imports for RAG ---\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d9d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully! ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhoge\\AppData\\Local\\Temp\\ipykernel_21468\\586850494.py:20: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "# Use 'cuda' if you have a GPU, otherwise 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# Load the Language Model (LLM) - Flan-T5 is excellent for instruction-following\n",
    "llm_model_id = \"google/flan-t5-base\" # Using 'base' for better performance on consumer hardware\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_id).to(device)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024, # Increased token limit for the detailed final analysis\n",
    "    device=0 if device == 'cuda' else -1\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "print(\"Models loaded successfully! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd5342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading financial guide from './documents'...\n",
      "Split guide into 112 text chunks.\n",
      "Creating embeddings and building FAISS index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cff14e76e36480eb49b6aed0525be89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index with <faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x00000239AF987750> > vectors created.\n",
      "FAISS index (knowledge base) is ready! ✅\n"
     ]
    }
   ],
   "source": [
    "# This is the knowledge base for your bot\n",
    "doc_directory = './documents'\n",
    "\n",
    "print(f\"Loading financial guide from '{doc_directory}'...\")\n",
    "loader = TextLoader(\"./manageMoney.txt\", encoding='utf8')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split guide into {len(all_chunks)} text chunks.\")\n",
    "\n",
    "print(\"Creating embeddings and building FAISS index...\")\n",
    "chunk_texts = [chunk.page_content for chunk in all_chunks]\n",
    "embeddings = embedding_model.encode(chunk_texts, show_progress_bar=True)\n",
    "\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index (knowledge base) is ready! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aae2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A much more efficient and concise constitution for the model\n",
    "FIN_FRIEND_CONSTITUTION_SHORT = \"\"\"\n",
    "**Persona:** You are Fin-Friend, an expert and empathetic financial guide in India. Your tone is supportive and simple.\n",
    "\n",
    "**Core Rules:**\n",
    "1.  **Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\"\n",
    "2.  **Use Context:** Base all strategies ONLY on the provided context from the financial guide.\n",
    "3.  **Disclaimer:** Every analysis MUST end with: \"This is for informational purposes only and is not financial advice. Please consult with a qualified financial advisor before making any decisions.\"\n",
    "\n",
    "**Your Task:**\n",
    "Analyze the user's data using the retrieved context and provide a structured financial health report with actionable educational points. Start your internal reasoning with \"Let's think step by step\".\n",
    "\"\"\"\n",
    "\n",
    "def format_user_data_for_llm(data):\n",
    "    \"\"\"\n",
    "    Formats the collected user data into a clean, human-readable string\n",
    "    for the language model.\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    for key, value in data.items():\n",
    "        title = key.replace('_', ' ').title()\n",
    "        \n",
    "        if isinstance(value, dict): # Correctly formats the nested expenses dictionary\n",
    "            report_lines.append(f\"**{title}:**\")\n",
    "            for sub_key, sub_value in value.items():\n",
    "                sub_title = sub_key.replace('_', ' ').title()\n",
    "                report_lines.append(f\"- {sub_title}: {sub_value}\")\n",
    "        else:\n",
    "            report_lines.append(f\"**{title}:**\\n{value}\")\n",
    "        \n",
    "        report_lines.append(\"\") # Adds a blank line for better readability\n",
    "        \n",
    "    return \"\\n\".join(report_lines)\n",
    "\n",
    "def get_user_input(prompt_text):\n",
    "    \"\"\"A helper function to handle user input.\"\"\"\n",
    "    return input(prompt_text + \"\\n> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5e53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm Fin-Friend... Let's get started!\n",
      "\n",
      "\n",
      "Great. Now let's break down your monthly expenses. Just enter the amount for each.\n",
      "\n",
      "Thank you for the information. Generating your personalized financial health report...\n"
     ]
    }
   ],
   "source": [
    "# --- Phase 1: Structured Data Gathering ---\n",
    "user_data = {}\n",
    "expenses = {}\n",
    "\n",
    "print(\"Hello! I'm Fin-Friend... Let's get started!\\n\")\n",
    "\n",
    "# Gather income\n",
    "user_data['income_salary'] = get_user_input(\"First, what is your fixed monthly take-home salary?\")\n",
    "user_data['income_other'] = get_user_input(\"Do you have any other sources of income (like freelance work or bonuses)?\")\n",
    "\n",
    "# Gather expenses one by one for clean data\n",
    "print(\"\\nGreat. Now let's break down your monthly expenses. Just enter the amount for each.\")\n",
    "expenses['rent_or_emi'] = get_user_input(\"- Rent or Home Loan EMI:\")\n",
    "expenses['utilities'] = get_user_input(\"- Electricity, Water, Gas:\")\n",
    "expenses['internet_and_phone'] = get_user_input(\"- Internet & Phone Bills:\")\n",
    "expenses['groceries'] = get_user_input(\"- Groceries:\")\n",
    "expenses['eating_out'] = get_user_input(\"- Eating Out/Ordering In:\")\n",
    "expenses['transport'] = get_user_input(\"- Fuel/Public Transport:\")\n",
    "expenses['shopping'] = get_user_input(\"- Shopping (Clothes, etc.):\")\n",
    "expenses['entertainment'] = get_user_input(\"- Entertainment & Subscriptions:\")\n",
    "user_data['expenses_structured'] = expenses\n",
    "\n",
    "# Gather goals, investments, and debts\n",
    "user_data['financial_goals'] = get_user_input(\"\\nWhat are your major financial goals (e.g., vacation, car, retirement)?\")\n",
    "user_data['current_investments'] = get_user_input(\"\\nBriefly, what investments do you currently have (e.g., Mutual Funds, PPF, Stocks)?\")\n",
    "user_data['outstanding_debts'] = get_user_input(\"\\nBriefly, what outstanding debts do you have (e.g., Credit Card, Personal Loan)?\")\n",
    "\n",
    "print(\"\\nThank you for the information. Generating your personalized financial health report...\")\n",
    "\n",
    "# --- Phase 2: RAG-Powered Analysis ---\n",
    "\n",
    "# Use the smart formatting function to create a clean report for the LLM\n",
    "formatted_user_data = format_user_data_for_llm(user_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944cf7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Your Financial Health Report ---\n",
      "\n",
      "**Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 3. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 4. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 5. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 6. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 7. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 8. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 9. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 10. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\"\n"
     ]
    }
   ],
   "source": [
    "# The query used to find relevant information from your financial guide\n",
    "analysis_query = \"Provide a comprehensive financial health check-up, including analysis of cash flow, savings rate, and debt. Offer educational strategies on budgeting, debt management, and investing based on this user's data.\"\n",
    "\n",
    "# Retrieve relevant context from the FAISS knowledge base\n",
    "query_embedding = embedding_model.encode([analysis_query])\n",
    "k = 3 # Retrieve top 3 most relevant chunks to save tokens\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "retrieved_context = \"\\n\\n\".join([all_chunks[i].page_content for i in indices[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e6ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final prompt template\n",
    "final_prompt_template = \"\"\"\n",
    "{constitution}\n",
    "\n",
    "---\n",
    "**RETRIEVED CONTEXT FROM THE FINANCIAL GUIDE:**\n",
    "{retrieved_context}\n",
    "---\n",
    "**USER'S FINANCIAL DATA:**\n",
    "{user_data}\n",
    "---\n",
    "**YOUR TASK:**\n",
    "Based on your constitution and the retrieved context, perform a complete financial health analysis for the user and provide actionable educational information.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b9a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_template(final_prompt_template)\n",
    "\n",
    "# Create and invoke the final analysis chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f50a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_chain = final_prompt | llm | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5af84e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Your Financial Health Report ---\n",
      "\n",
      "**Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 3. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 4. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 5. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 6. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 7. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 8. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 9. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\" 10. **Your Task:** Analyze, Don't Advise:** Your goal is a financial health check-up. NEVER give direct financial advice. Frame outputs as \"educational information\" or \"examples.\"\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with the clean, formatted data\n",
    "final_report = analysis_chain.invoke({\n",
    "    \"constitution\": FIN_FRIEND_CONSTITUTION_SHORT,\n",
    "    \"retrieved_context\": retrieved_context,\n",
    "    \"user_data\": formatted_user_data\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Your Financial Health Report ---\\n\")\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
